{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTH-IDS: A Multi-Tiered Hybrid Intrusion Detection System for Internet of Vehicles\n",
    "This is the code for the paper entitled \"[**MTH-IDS: A Multi-Tiered Hybrid Intrusion Detection System for Internet of Vehicles**](https://arxiv.org/pdf/2105.13289.pdf)\" accepted in IEEE Internet of Things Journal.  \n",
    "Authors: Li Yang (liyanghart@gmail.com), Abdallah Moubayed, and Abdallah Shami  \n",
    "Organization: The Optimized Computing and Communications (OC2) Lab, ECE Department, Western University\n",
    "\n",
    "If you find this repository useful in your research, please cite:  \n",
    "L. Yang, A. Moubayed, and A. Shami, “MTH-IDS: A Multi-Tiered Hybrid Intrusion Detection System for Internet of Vehicles,” IEEE Internet of Things Journal, vol. 9, no. 1, pp. 616-632, Jan.1, 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries ----- ADDED SOME IMPORTS 4371 -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Requirement already satisfied: hyperopt in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: scikit-optimize in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from hyperopt) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from hyperopt) (1.13.1)\n",
      "Requirement already satisfied: six in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from hyperopt) (3.2.1)\n",
      "Requirement already satisfied: future in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from hyperopt) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from hyperopt) (4.66.6)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from hyperopt) (3.1.0)\n",
      "Requirement already satisfied: py4j in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from hyperopt) (0.10.9.7)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-optimize) (1.4.2)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-optimize) (24.9.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-optimize) (1.5.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-optimize) (24.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\logan\\anaconda3\\envs\\myenv\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Collecting git+https://github.com/SantiagoEG/FCBF_module.git\n",
      "  Cloning https://github.com/SantiagoEG/FCBF_module.git to c:\\users\\logan\\appdata\\local\\temp\\pip-req-build-dtrpdsz7\n",
      "  Resolved https://github.com/SantiagoEG/FCBF_module.git to commit 092b60b65ee6ceaf9b0227d12b575f2a3336b287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/SantiagoEG/FCBF_module.git 'C:\\Users\\Logan\\AppData\\Local\\Temp\\pip-req-build-dtrpdsz7'\n",
      "ERROR: git+https://github.com/SantiagoEG/FCBF_module.git does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "\n",
    "# imports below are from 4371 group to make file work\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "# Core data manipulation and scientific libraries\n",
    "!pip install numpy pandas\n",
    "\n",
    "# Data visualization libraries\n",
    "!pip install seaborn matplotlib\n",
    "\n",
    "# Machine learning libraries\n",
    "!pip install scikit-learn xgboost\n",
    "\n",
    "# Imbalanced data handling\n",
    "!pip install imbalanced-learn\n",
    "\n",
    "# Hyperparameter optimization libraries\n",
    "!pip install hyperopt scikit-optimize\n",
    "\n",
    "# (Optional) Additional dependencies for compatibility\n",
    "!pip install scipy\n",
    "\n",
    "# Custom module FCBF (if available locally, or if it's a GitHub repo, use the clone URL)\n",
    "# Replace \"URL_TO_FCBF_MODULE\" with the actual URL or location if it's on GitHub or a local file\n",
    "!pip install git+https://github.com/SantiagoEG/FCBF_module.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Isolation Forest Import -- 4371\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the sampled CICIDS2017 dataset\n",
    "The CICIDS2017 dataset is publicly available at: https://www.unb.ca/cic/datasets/ids-2017.html  \n",
    "Due to the large size of this dataset, the sampled subsets of CICIDS2017 is used. The subsets are in the \"data\" folder.  \n",
    "If you want to use this code on other datasets (e.g., CAN-intrusion dataset), just change the dataset name and follow the same steps. The models in this code are generic models that can be used in any intrusion detection/network traffic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read dataset\n",
    "df = pd.read_csv('./data/CICIDS2017_sample.csv') \n",
    "# The results in this code is based on the original CICIDS2017 dataset. Please go to cell [21] if you work on the sampled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>17.677670</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142377</td>\n",
       "      <td>46</td>\n",
       "      <td>62</td>\n",
       "      <td>1325</td>\n",
       "      <td>105855</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>28.804348</td>\n",
       "      <td>111.407285</td>\n",
       "      <td>4344</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118873</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>1169</td>\n",
       "      <td>45025</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>50.826087</td>\n",
       "      <td>156.137367</td>\n",
       "      <td>2896</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143577</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "      <td>1301</td>\n",
       "      <td>107289</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>30.255814</td>\n",
       "      <td>115.178969</td>\n",
       "      <td>4344</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143745</td>\n",
       "      <td>49</td>\n",
       "      <td>59</td>\n",
       "      <td>1331</td>\n",
       "      <td>110185</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>27.163265</td>\n",
       "      <td>108.067176</td>\n",
       "      <td>4344</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56656</th>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>232</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56657</th>\n",
       "      <td>133288</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>482</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>241</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56658</th>\n",
       "      <td>11507694</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "      <td>3525</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>201.246118</td>\n",
       "      <td>3525</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>893.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>893</td>\n",
       "      <td>893</td>\n",
       "      <td>6503640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6503640</td>\n",
       "      <td>6503640</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56659</th>\n",
       "      <td>11507707</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>416</td>\n",
       "      <td>11632</td>\n",
       "      <td>416</td>\n",
       "      <td>0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>147.078211</td>\n",
       "      <td>5792</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>897</td>\n",
       "      <td>897</td>\n",
       "      <td>6503122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6503122</td>\n",
       "      <td>6503122</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56660</th>\n",
       "      <td>11512204</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>326</td>\n",
       "      <td>11632</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>115.258405</td>\n",
       "      <td>10184</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>892</td>\n",
       "      <td>892</td>\n",
       "      <td>6507197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6507197</td>\n",
       "      <td>6507197</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56661 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0                  4                  2                       0   \n",
       "1             142377                 46                      62   \n",
       "2             118873                 23                      28   \n",
       "3             143577                 43                      55   \n",
       "4             143745                 49                      59   \n",
       "...              ...                ...                     ...   \n",
       "56656            234                  2                       2   \n",
       "56657         133288                  2                       2   \n",
       "56658       11507694                  5                       4   \n",
       "56659       11507707                  8                       6   \n",
       "56660       11512204                  8                       5   \n",
       "\n",
       "       Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "0                               37                            0   \n",
       "1                             1325                       105855   \n",
       "2                             1169                        45025   \n",
       "3                             1301                       107289   \n",
       "4                             1331                       110185   \n",
       "...                            ...                          ...   \n",
       "56656                           64                          232   \n",
       "56657                           94                          482   \n",
       "56658                          450                         3525   \n",
       "56659                          416                        11632   \n",
       "56660                          326                        11632   \n",
       "\n",
       "       Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                         31                      6               18.500000   \n",
       "1                        570                      0               28.804348   \n",
       "2                        570                      0               50.826087   \n",
       "3                        570                      0               30.255814   \n",
       "4                        570                      0               27.163265   \n",
       "...                      ...                    ...                     ...   \n",
       "56656                     32                     32               32.000000   \n",
       "56657                     47                     47               47.000000   \n",
       "56658                    450                      0               90.000000   \n",
       "56659                    416                      0               52.000000   \n",
       "56660                    326                      0               40.750000   \n",
       "\n",
       "       Fwd Packet Length Std  Bwd Packet Length Max  ...  \\\n",
       "0                  17.677670                      0  ...   \n",
       "1                 111.407285                   4344  ...   \n",
       "2                 156.137367                   2896  ...   \n",
       "3                 115.178969                   4344  ...   \n",
       "4                 108.067176                   4344  ...   \n",
       "...                      ...                    ...  ...   \n",
       "56656               0.000000                    116  ...   \n",
       "56657               0.000000                    241  ...   \n",
       "56658             201.246118                   3525  ...   \n",
       "56659             147.078211                   5792  ...   \n",
       "56660             115.258405                  10184  ...   \n",
       "\n",
       "       min_seg_size_forward  Active Mean  Active Std  Active Max  Active Min  \\\n",
       "0                        20          0.0         0.0           0           0   \n",
       "1                        20          0.0         0.0           0           0   \n",
       "2                        32          0.0         0.0           0           0   \n",
       "3                        20          0.0         0.0           0           0   \n",
       "4                        20          0.0         0.0           0           0   \n",
       "...                     ...          ...         ...         ...         ...   \n",
       "56656                    32          0.0         0.0           0           0   \n",
       "56657                    32          0.0         0.0           0           0   \n",
       "56658                    32        893.0         0.0         893         893   \n",
       "56659                    32        897.0         0.0         897         897   \n",
       "56660                    32        892.0         0.0         892         892   \n",
       "\n",
       "       Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
       "0            0.0       0.0         0         0  BENIGN  \n",
       "1            0.0       0.0         0         0  BENIGN  \n",
       "2            0.0       0.0         0         0  BENIGN  \n",
       "3            0.0       0.0         0         0  BENIGN  \n",
       "4            0.0       0.0         0         0  BENIGN  \n",
       "...          ...       ...       ...       ...     ...  \n",
       "56656        0.0       0.0         0         0  BENIGN  \n",
       "56657        0.0       0.0         0         0  BENIGN  \n",
       "56658  6503640.0       0.0   6503640   6503640     DoS  \n",
       "56659  6503122.0       0.0   6503122   6503122     DoS  \n",
       "56660  6507197.0       0.0   6507197   6507197     DoS  \n",
       "\n",
       "[56661 rows x 78 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "BENIGN          22731\n",
       "DoS             19035\n",
       "PortScan         7946\n",
       "BruteForce       2767\n",
       "WebAttack        2180\n",
       "Bot              1966\n",
       "Infiltration       36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (normalization and padding values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score normalization\n",
    "features = df.dtypes[df.dtypes != 'object'].index\n",
    "df[features] = df[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# Fill empty values by 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sampling\n",
    "Due to the space limit of GitHub files and the large size of network traffic data, we sample a small-sized subset for model learning using **k-means cluster sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    22731\n",
       "3    19035\n",
       "5     7946\n",
       "2     2767\n",
       "6     2180\n",
       "1     1966\n",
       "4       36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain the minority class instances and sample the majority class instances\n",
    "df_minor = df[(df['Label']==6)|(df['Label']==1)|(df['Label']==4)]\n",
    "df_major = df.drop(df_minor.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_major.drop(['Label'],axis=1) \n",
    "y = df_major.iloc[:, -1].values.reshape(-1,1)\n",
    "y=np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use k-means to cluster the data samples and select a proportion of data from each cluster\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "kmeans = MiniBatchKMeans(n_clusters=1000, random_state=0).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "klabel=kmeans.labels_\n",
    "df_major['klabel']=klabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "klabel\n",
       "20     482\n",
       "842    411\n",
       "312    348\n",
       "324    337\n",
       "745    334\n",
       "      ... \n",
       "973      1\n",
       "727      1\n",
       "594      1\n",
       "410      1\n",
       "100      1\n",
       "Name: count, Length: 979, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_major['klabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df_major)\n",
    "cols.insert(78, cols.pop(cols.index('Label')))\n",
    "df_major = df_major.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>klabel</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.528470</td>\n",
       "      <td>-0.068426</td>\n",
       "      <td>-0.081806</td>\n",
       "      <td>-0.032573</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-0.202326</td>\n",
       "      <td>-0.085798</td>\n",
       "      <td>-0.141625</td>\n",
       "      <td>-0.176448</td>\n",
       "      <td>-0.559719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.524593</td>\n",
       "      <td>0.704878</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.027749</td>\n",
       "      <td>0.920410</td>\n",
       "      <td>0.603275</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.082434</td>\n",
       "      <td>0.240596</td>\n",
       "      <td>1.006302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.525233</td>\n",
       "      <td>0.300651</td>\n",
       "      <td>0.339163</td>\n",
       "      <td>0.020443</td>\n",
       "      <td>0.363712</td>\n",
       "      <td>0.603275</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>0.044064</td>\n",
       "      <td>0.439619</td>\n",
       "      <td>0.484295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.524560</td>\n",
       "      <td>0.652153</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.026625</td>\n",
       "      <td>0.933533</td>\n",
       "      <td>0.603275</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.074097</td>\n",
       "      <td>0.257378</td>\n",
       "      <td>1.006302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.524555</td>\n",
       "      <td>0.757604</td>\n",
       "      <td>0.805237</td>\n",
       "      <td>0.028030</td>\n",
       "      <td>0.960037</td>\n",
       "      <td>0.603275</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.091861</td>\n",
       "      <td>0.225734</td>\n",
       "      <td>1.006302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56656</th>\n",
       "      <td>-0.528463</td>\n",
       "      <td>-0.068426</td>\n",
       "      <td>-0.051737</td>\n",
       "      <td>-0.031309</td>\n",
       "      <td>-0.046220</td>\n",
       "      <td>-0.200831</td>\n",
       "      <td>0.457498</td>\n",
       "      <td>-0.064078</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.517901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56657</th>\n",
       "      <td>-0.524840</td>\n",
       "      <td>-0.068426</td>\n",
       "      <td>-0.051737</td>\n",
       "      <td>-0.029904</td>\n",
       "      <td>-0.043932</td>\n",
       "      <td>-0.178412</td>\n",
       "      <td>0.770939</td>\n",
       "      <td>0.022086</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.472838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56658</th>\n",
       "      <td>-0.215111</td>\n",
       "      <td>-0.015701</td>\n",
       "      <td>-0.021667</td>\n",
       "      <td>-0.013231</td>\n",
       "      <td>-0.016083</td>\n",
       "      <td>0.423920</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>0.269089</td>\n",
       "      <td>0.640328</td>\n",
       "      <td>0.711051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108682</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.127669</td>\n",
       "      <td>-0.093554</td>\n",
       "      <td>-0.256386</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.269448</td>\n",
       "      <td>-0.238252</td>\n",
       "      <td>551</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56659</th>\n",
       "      <td>-0.215111</td>\n",
       "      <td>0.037025</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>-0.014823</td>\n",
       "      <td>0.058109</td>\n",
       "      <td>0.373103</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>0.050807</td>\n",
       "      <td>0.399311</td>\n",
       "      <td>1.528310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108677</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.127664</td>\n",
       "      <td>-0.093548</td>\n",
       "      <td>-0.256402</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.269464</td>\n",
       "      <td>-0.238268</td>\n",
       "      <td>702</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56660</th>\n",
       "      <td>-0.214989</td>\n",
       "      <td>0.037025</td>\n",
       "      <td>-0.006633</td>\n",
       "      <td>-0.019038</td>\n",
       "      <td>0.058109</td>\n",
       "      <td>0.238587</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.013815</td>\n",
       "      <td>0.257731</td>\n",
       "      <td>3.111635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108683</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.127670</td>\n",
       "      <td>-0.093555</td>\n",
       "      <td>-0.256275</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.269340</td>\n",
       "      <td>-0.238140</td>\n",
       "      <td>253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52479 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0          -0.528470          -0.068426               -0.081806   \n",
       "1          -0.524593           0.704878                0.850340   \n",
       "2          -0.525233           0.300651                0.339163   \n",
       "3          -0.524560           0.652153                0.745098   \n",
       "4          -0.524555           0.757604                0.805237   \n",
       "...              ...                ...                     ...   \n",
       "56656      -0.528463          -0.068426               -0.051737   \n",
       "56657      -0.524840          -0.068426               -0.051737   \n",
       "56658      -0.215111          -0.015701               -0.021667   \n",
       "56659      -0.215111           0.037025                0.008402   \n",
       "56660      -0.214989           0.037025               -0.006633   \n",
       "\n",
       "       Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "0                        -0.032573                    -0.048343   \n",
       "1                         0.027749                     0.920410   \n",
       "2                         0.020443                     0.363712   \n",
       "3                         0.026625                     0.933533   \n",
       "4                         0.028030                     0.960037   \n",
       "...                            ...                          ...   \n",
       "56656                    -0.031309                    -0.046220   \n",
       "56657                    -0.029904                    -0.043932   \n",
       "56658                    -0.013231                    -0.016083   \n",
       "56659                    -0.014823                     0.058109   \n",
       "56660                    -0.019038                     0.058109   \n",
       "\n",
       "       Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                  -0.202326              -0.085798               -0.141625   \n",
       "1                   0.603275              -0.211174               -0.082434   \n",
       "2                   0.603275              -0.211174                0.044064   \n",
       "3                   0.603275              -0.211174               -0.074097   \n",
       "4                   0.603275              -0.211174               -0.091861   \n",
       "...                      ...                    ...                     ...   \n",
       "56656              -0.200831               0.457498               -0.064078   \n",
       "56657              -0.178412               0.770939                0.022086   \n",
       "56658               0.423920              -0.211174                0.269089   \n",
       "56659               0.373103              -0.211174                0.050807   \n",
       "56660               0.238587              -0.211174               -0.013815   \n",
       "\n",
       "       Fwd Packet Length Std  Bwd Packet Length Max  ...  Active Mean  \\\n",
       "0                  -0.176448              -0.559719  ...    -0.109889   \n",
       "1                   0.240596               1.006302  ...    -0.109889   \n",
       "2                   0.439619               0.484295  ...    -0.109889   \n",
       "3                   0.257378               1.006302  ...    -0.109889   \n",
       "4                   0.225734               1.006302  ...    -0.109889   \n",
       "...                      ...                    ...  ...          ...   \n",
       "56656              -0.255104              -0.517901  ...    -0.109889   \n",
       "56657              -0.255104              -0.472838  ...    -0.109889   \n",
       "56658               0.640328               0.711051  ...    -0.108682   \n",
       "56659               0.399311               1.528310  ...    -0.108677   \n",
       "56660               0.257731               3.111635  ...    -0.108683   \n",
       "\n",
       "       Active Std  Active Max  Active Min  Idle Mean  Idle Std  Idle Max  \\\n",
       "0       -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "1       -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "2       -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "3       -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "4       -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "...           ...         ...         ...        ...       ...       ...   \n",
       "56656   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "56657   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "56658   -0.081786   -0.127669   -0.093554  -0.256386 -0.137651 -0.269448   \n",
       "56659   -0.081786   -0.127664   -0.093548  -0.256402 -0.137651 -0.269464   \n",
       "56660   -0.081786   -0.127670   -0.093555  -0.256275 -0.137651 -0.269340   \n",
       "\n",
       "       Idle Min  klabel  Label  \n",
       "0     -0.442057     402      0  \n",
       "1     -0.442057     359      0  \n",
       "2     -0.442057     191      0  \n",
       "3     -0.442057     359      0  \n",
       "4     -0.442057     359      0  \n",
       "...         ...     ...    ...  \n",
       "56656 -0.442057     231      0  \n",
       "56657 -0.442057     934      0  \n",
       "56658 -0.238252     551      3  \n",
       "56659 -0.238268     702      3  \n",
       "56660 -0.238140     253      3  \n",
       "\n",
       "[52479 rows x 79 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typicalSampling(group):\n",
    "    name = group.name\n",
    "    frac = 0.008\n",
    "    return group.sample(frac=frac)\n",
    "\n",
    "result = df_major.groupby(\n",
    "    'klabel', group_keys=False\n",
    ").apply(typicalSampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    123\n",
       "3    117\n",
       "5     55\n",
       "2     19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>klabel</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47511</th>\n",
       "      <td>1.804249</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>-0.019460</td>\n",
       "      <td>0.057771</td>\n",
       "      <td>0.216168</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.045568</td>\n",
       "      <td>0.205127</td>\n",
       "      <td>1.528310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108508</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.127531</td>\n",
       "      <td>-0.093365</td>\n",
       "      <td>2.198255</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>2.120284</td>\n",
       "      <td>2.234135</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53786</th>\n",
       "      <td>-0.527628</td>\n",
       "      <td>-0.068426</td>\n",
       "      <td>-0.051737</td>\n",
       "      <td>-0.030653</td>\n",
       "      <td>-0.046659</td>\n",
       "      <td>-0.190369</td>\n",
       "      <td>0.603771</td>\n",
       "      <td>-0.023868</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.526553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5186</th>\n",
       "      <td>-0.492616</td>\n",
       "      <td>-0.050851</td>\n",
       "      <td>-0.021667</td>\n",
       "      <td>-0.033088</td>\n",
       "      <td>0.057881</td>\n",
       "      <td>-0.218767</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.198110</td>\n",
       "      <td>-0.209439</td>\n",
       "      <td>3.620304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5475</th>\n",
       "      <td>-0.363294</td>\n",
       "      <td>-0.015701</td>\n",
       "      <td>-0.081806</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-0.239691</td>\n",
       "      <td>-0.085798</td>\n",
       "      <td>-0.213428</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.559719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107188</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.126491</td>\n",
       "      <td>-0.091937</td>\n",
       "      <td>-0.270068</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.282768</td>\n",
       "      <td>-0.252032</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>-0.499849</td>\n",
       "      <td>-0.015701</td>\n",
       "      <td>-0.081806</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-0.239691</td>\n",
       "      <td>-0.085798</td>\n",
       "      <td>-0.213428</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.559719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>-0.528461</td>\n",
       "      <td>-0.068426</td>\n",
       "      <td>-0.051737</td>\n",
       "      <td>-0.030747</td>\n",
       "      <td>-0.047098</td>\n",
       "      <td>-0.191864</td>\n",
       "      <td>0.582875</td>\n",
       "      <td>-0.029612</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.535205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5814</th>\n",
       "      <td>-0.200489</td>\n",
       "      <td>-0.015701</td>\n",
       "      <td>-0.081806</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-0.239691</td>\n",
       "      <td>-0.085798</td>\n",
       "      <td>-0.213428</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.559719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108480</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.127510</td>\n",
       "      <td>-0.093336</td>\n",
       "      <td>-0.085382</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.102966</td>\n",
       "      <td>-0.066012</td>\n",
       "      <td>982</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52568</th>\n",
       "      <td>-0.528383</td>\n",
       "      <td>-0.015701</td>\n",
       "      <td>-0.081806</td>\n",
       "      <td>-0.034306</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-0.248659</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.247894</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.559719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>991</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>-0.528469</td>\n",
       "      <td>-0.086001</td>\n",
       "      <td>-0.066771</td>\n",
       "      <td>-0.034212</td>\n",
       "      <td>-0.048288</td>\n",
       "      <td>-0.245670</td>\n",
       "      <td>-0.169382</td>\n",
       "      <td>-0.236405</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.557556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>997</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10475</th>\n",
       "      <td>-0.528469</td>\n",
       "      <td>-0.086001</td>\n",
       "      <td>-0.066771</td>\n",
       "      <td>-0.034212</td>\n",
       "      <td>-0.048288</td>\n",
       "      <td>-0.245670</td>\n",
       "      <td>-0.169382</td>\n",
       "      <td>-0.236405</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.557556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "47511       1.804249           0.054600                0.008402   \n",
       "53786      -0.527628          -0.068426               -0.051737   \n",
       "5186       -0.492616          -0.050851               -0.021667   \n",
       "5475       -0.363294          -0.015701               -0.081806   \n",
       "6591       -0.499849          -0.015701               -0.081806   \n",
       "...              ...                ...                     ...   \n",
       "5271       -0.528461          -0.068426               -0.051737   \n",
       "5814       -0.200489          -0.015701               -0.081806   \n",
       "52568      -0.528383          -0.015701               -0.081806   \n",
       "9860       -0.528469          -0.086001               -0.066771   \n",
       "10475      -0.528469          -0.086001               -0.066771   \n",
       "\n",
       "       Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "47511                    -0.019460                     0.057771   \n",
       "53786                    -0.030653                    -0.046659   \n",
       "5186                     -0.033088                     0.057881   \n",
       "5475                     -0.032901                    -0.048343   \n",
       "6591                     -0.032901                    -0.048343   \n",
       "...                            ...                          ...   \n",
       "5271                     -0.030747                    -0.047098   \n",
       "5814                     -0.032901                    -0.048343   \n",
       "52568                    -0.034306                    -0.048343   \n",
       "9860                     -0.034212                    -0.048288   \n",
       "10475                    -0.034212                    -0.048288   \n",
       "\n",
       "       Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "47511               0.216168              -0.211174               -0.045568   \n",
       "53786              -0.190369               0.603771               -0.023868   \n",
       "5186               -0.218767              -0.211174               -0.198110   \n",
       "5475               -0.239691              -0.085798               -0.213428   \n",
       "6591               -0.239691              -0.085798               -0.213428   \n",
       "...                      ...                    ...                     ...   \n",
       "5271               -0.191864               0.582875               -0.029612   \n",
       "5814               -0.239691              -0.085798               -0.213428   \n",
       "52568              -0.248659              -0.211174               -0.247894   \n",
       "9860               -0.245670              -0.169382               -0.236405   \n",
       "10475              -0.245670              -0.169382               -0.236405   \n",
       "\n",
       "       Fwd Packet Length Std  Bwd Packet Length Max  ...  Active Mean  \\\n",
       "47511               0.205127               1.528310  ...    -0.108508   \n",
       "53786              -0.255104              -0.526553  ...    -0.109889   \n",
       "5186               -0.209439               3.620304  ...    -0.109889   \n",
       "5475               -0.255104              -0.559719  ...    -0.107188   \n",
       "6591               -0.255104              -0.559719  ...    -0.109889   \n",
       "...                      ...                    ...  ...          ...   \n",
       "5271               -0.255104              -0.535205  ...    -0.109889   \n",
       "5814               -0.255104              -0.559719  ...    -0.108480   \n",
       "52568              -0.255104              -0.559719  ...    -0.109889   \n",
       "9860               -0.255104              -0.557556  ...    -0.109889   \n",
       "10475              -0.255104              -0.557556  ...    -0.109889   \n",
       "\n",
       "       Active Std  Active Max  Active Min  Idle Mean  Idle Std  Idle Max  \\\n",
       "47511   -0.081786   -0.127531   -0.093365   2.198255 -0.137651  2.120284   \n",
       "53786   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "5186    -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "5475    -0.081786   -0.126491   -0.091937  -0.270068 -0.137651 -0.282768   \n",
       "6591    -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "...           ...         ...         ...        ...       ...       ...   \n",
       "5271    -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "5814    -0.081786   -0.127510   -0.093336  -0.085382 -0.137651 -0.102966   \n",
       "52568   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "9860    -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "10475   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "\n",
       "       Idle Min  klabel  Label  \n",
       "47511  2.234135       2      3  \n",
       "53786 -0.442057       8      0  \n",
       "5186  -0.442057      10      3  \n",
       "5475  -0.252032      11      3  \n",
       "6591  -0.442057      12      3  \n",
       "...         ...     ...    ...  \n",
       "5271  -0.442057     979      0  \n",
       "5814  -0.066012     982      3  \n",
       "52568 -0.442057     991      3  \n",
       "9860  -0.442057     997      5  \n",
       "10475 -0.442057     999      5  \n",
       "\n",
       "[314 rows x 79 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4371 Had to modify the file below because the recommended way to combine DataFrames in recent versions of pandas is by using the pandas.concat() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames concatenated successfully.\n",
      "Updated DataFrame head:\n",
      "   Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
      "0       1.804249           0.054600                0.008402   \n",
      "1      -0.527628          -0.068426               -0.051737   \n",
      "2      -0.492616          -0.050851               -0.021667   \n",
      "3      -0.363294          -0.015701               -0.081806   \n",
      "4      -0.499849          -0.015701               -0.081806   \n",
      "\n",
      "   Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
      "0                    -0.019460                     0.057771   \n",
      "1                    -0.030653                    -0.046659   \n",
      "2                    -0.033088                     0.057881   \n",
      "3                    -0.032901                    -0.048343   \n",
      "4                    -0.032901                    -0.048343   \n",
      "\n",
      "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
      "0               0.216168              -0.211174               -0.045568   \n",
      "1              -0.190369               0.603771               -0.023868   \n",
      "2              -0.218767              -0.211174               -0.198110   \n",
      "3              -0.239691              -0.085798               -0.213428   \n",
      "4              -0.239691              -0.085798               -0.213428   \n",
      "\n",
      "   Fwd Packet Length Std  Bwd Packet Length Max  ...  Active Mean  Active Std  \\\n",
      "0               0.205127               1.528310  ...    -0.108508   -0.081786   \n",
      "1              -0.255104              -0.526553  ...    -0.109889   -0.081786   \n",
      "2              -0.209439               3.620304  ...    -0.109889   -0.081786   \n",
      "3              -0.255104              -0.559719  ...    -0.107188   -0.081786   \n",
      "4              -0.255104              -0.559719  ...    -0.109889   -0.081786   \n",
      "\n",
      "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  klabel  \\\n",
      "0   -0.127531   -0.093365   2.198255 -0.137651  2.120284  2.234135     2.0   \n",
      "1   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440 -0.442057     8.0   \n",
      "2   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440 -0.442057    10.0   \n",
      "3   -0.126491   -0.091937  -0.270068 -0.137651 -0.282768 -0.252032    11.0   \n",
      "4   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440 -0.442057    12.0   \n",
      "\n",
      "   Label  \n",
      "0      3  \n",
      "1      0  \n",
      "2      3  \n",
      "3      3  \n",
      "4      3  \n",
      "\n",
      "[5 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'result' and 'df_minor' are already defined and loaded\n",
    "\n",
    "# No need to drop 'klabel' since it doesn't exist\n",
    "# If you need to drop another column, ensure it exists\n",
    "# For example, to drop 'Label' (only if intended, which is usually not the case):\n",
    "# result = result.drop(['Label'], axis=1)\n",
    "\n",
    "# Concatenate 'result' and 'df_minor' DataFrames\n",
    "result = pd.concat([result, df_minor], ignore_index=True)\n",
    "\n",
    "print(\"DataFrames concatenated successfully.\")\n",
    "print(\"Updated DataFrame head:\")\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./data/CICIDS2017_sample_km.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Duration                     0\n",
      "Total Fwd Packets                 0\n",
      "Total Backward Packets            0\n",
      "Total Length of Fwd Packets       0\n",
      "Total Length of Bwd Packets       0\n",
      "                               ... \n",
      "Idle Std                          0\n",
      "Idle Max                          0\n",
      "Idle Min                          0\n",
      "klabel                         4182\n",
      "Label                             0\n",
      "Length: 79, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read the sampled dataset\n",
    "df=pd.read_csv('./data/CICIDS2017_sample_km.csv')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----- ADDED LINES BELOW 4371 TO FIX ISSUE WITH ValueError: Input X contains NaN. ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create an imputer object with the desired strategy (mean, median, most_frequent)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Apply the imputer to the DataFrame\n",
    "df[df.columns] = imputer.fit_transform(df)\n",
    "\n",
    "# fixed the issue by using SimpleImputer to replace the NaN values in your dataset with \n",
    "# meaningful statistical estimates (like the mean of each feature column). This transformation eliminated missing \n",
    "# values from the dataset, which allowed mutual_info_classif to execute without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Label'],axis=1).values\n",
    "y = df.iloc[:, -1].values.reshape(-1,1)\n",
    "y=np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 0,stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection by information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "importances = mutual_info_classif(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of importance scores\n",
    "f_list = sorted(zip(map(lambda x: round(x, 4), importances), features), reverse=True)\n",
    "Sum = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list)):\n",
    "    Sum = Sum + f_list[i][0]\n",
    "    fs.append(f_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the important features from top to bottom until the accumulated importance reaches 90%\n",
    "f_list2 = sorted(zip(map(lambda x: round(x, 4), importances/Sum), features), reverse=True)\n",
    "Sum2 = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list2)):\n",
    "    Sum2 = Sum2 + f_list2[i][0]\n",
    "    fs.append(f_list2[i][1])\n",
    "    if Sum2>=0.9:\n",
    "        break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs = df[fs].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4496, 42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection by Fast Correlation Based Filter (FCBF)\n",
    "\n",
    "The module is imported from the GitHub repo: https://github.com/SantiagoEG/FCBF_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FCBF_module import FCBF, FCBFK, FCBFiP, get_i\n",
    "fcbf = FCBFK(k = 20)\n",
    "#fcbf.fit(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fss = fcbf.fit_transform(X_fs,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4496, 20)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest Implementation\n",
    "\n",
    "After performing feature selection using Information Gain (IG) and Fast Correlation-Based Filter (FCBF), we apply the Isolation Forest to detect and filter out anomalies in our dataset. This step enhances our model's ability to differentiate between actual threats and benign unusual behavior by removing potential outliers before training.\n",
    "\n",
    "n_estimators=100: Number of trees in the forest.\n",
    "contamination='auto': Let the algorithm decide the proportion of anomalies.\n",
    "random_state=42: For reproducibility.\n",
    "Anomaly Detection:\n",
    "\n",
    "anomaly_predictions == 1: Inliers (normal instances).\n",
    "anomaly_predictions == -1: Outliers (anomalies).\n",
    "Filtering Data:\n",
    "\n",
    "X_filtered: Contains only the inlier instances.\n",
    "y_filtered: Corresponding labels for inliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Isolation Forest\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "iso_forest.fit(X_fss)\n",
    "\n",
    "# Obtain anomaly scores and predictions\n",
    "anomaly_scores = iso_forest.decision_function(X_fss)\n",
    "anomaly_predictions = iso_forest.predict(X_fss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Anomaly Scores\n",
    "\n",
    "To understand how the Isolation Forest has assigned anomaly scores to our data points, we visualize the distribution of these scores. This helps us assess the threshold and proportion of data considered anomalous, providing insights into the filtering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize anomaly scores\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(anomaly_scores, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Anomaly Scores')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Out Detected Anomalies\n",
    "\n",
    "Using the predictions from the Isolation Forest, we filter out the anomalies (outliers) from our dataset. We retain only the inlier data points (those predicted as normal) for model training. This step aims to improve the quality of our training data by removing noise and potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out anomalies\n",
    "inlier_mask = anomaly_predictions == 1\n",
    "X_filtered = X_fss[inlier_mask]\n",
    "y_filtered = y[inlier_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-split train & test sets after feature selection and Isolation Forest\n",
    "\n",
    "Updating Train-Test Split with Filtered Data\n",
    "\n",
    "After filtering out anomalies, we perform the train-test split on the cleaned dataset (X_filtered, y_filtered). This ensures that our training and testing sets contain only the inlier data points, which should enhance model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the filtered dataset - modified for isolation forest\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_filtered, y_filtered, train_size=0.8, test_size=0.2, random_state=0, stratify=y_filtered\n",
    ")\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE to solve class-imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Adjust SMOTE to handle smaller classes by reducing k_neighbors\n",
    "smote = SMOTE(n_jobs=-1, sampling_strategy={2: 1000, 4: 1000}, k_neighbors=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training four base learners: decision tree, random forest, extra trees, XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = xgb.XGBClassifier(n_estimators = 10)\n",
    "xg.fit(X_train,y_train)\n",
    "xg_score=xg.score(X_test,y_test)\n",
    "y_predict=xg.predict(X_test)\n",
    "y_true=y_test\n",
    "print('Accuracy of XGBoost: '+ str(xg_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_true, y_predict, average='weighted') \n",
    "print('Precision of XGBoost: '+(str(precision)))\n",
    "print('Recall of XGBoost: '+(str(recall)))\n",
    "print('F1-score of XGBoost: '+(str(fscore)))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization (HPO) of XGBoost using Bayesian optimization with tree-based Parzen estimator (BO-TPE)\n",
    "Based on the GitHub repo for HPO: https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']), \n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'learning_rate':  abs(float(params['learning_rate'])),\n",
    "\n",
    "    }\n",
    "    clf = xgb.XGBClassifier( **params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return {'loss':-score, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 100, 5),\n",
    "    'max_depth': hp.quniform('max_depth', 4, 100, 1),\n",
    "    'learning_rate': hp.normal('learning_rate', 0.01, 0.9),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"XGBoost: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = xgb.XGBClassifier(learning_rate= 0.7340229699980686, n_estimators = 70, max_depth = 14)\n",
    "xg.fit(X_train,y_train)\n",
    "xg_score=xg.score(X_test,y_test)\n",
    "y_predict=xg.predict(X_test)\n",
    "y_true=y_test\n",
    "print('Accuracy of XGBoost: '+ str(xg_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_true, y_predict, average='weighted') \n",
    "print('Precision of XGBoost: '+(str(precision)))\n",
    "print('Recall of XGBoost: '+(str(recall)))\n",
    "print('F1-score of XGBoost: '+(str(fscore)))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_train=xg.predict(X_train)\n",
    "xg_test=xg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 0)\n",
    "rf.fit(X_train,y_train) \n",
    "rf_score=rf.score(X_test,y_test)\n",
    "y_predict=rf.predict(X_test)\n",
    "y_true=y_test\n",
    "print('Accuracy of RF: '+ str(rf_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_true, y_predict, average='weighted') \n",
    "print('Precision of RF: '+(str(precision)))\n",
    "print('Recall of RF: '+(str(recall)))\n",
    "print('F1-score of RF: '+(str(fscore)))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization (HPO) of random forest using Bayesian optimization with tree-based Parzen estimator (BO-TPE)\n",
    "Based on the GitHub repo for HPO: https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization of random forest\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']), \n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'max_features': int(params['max_features']),\n",
    "        \"min_samples_split\":int(params['min_samples_split']),\n",
    "        \"min_samples_leaf\":int(params['min_samples_leaf']),\n",
    "        \"criterion\":str(params['criterion'])\n",
    "    }\n",
    "    clf = RandomForestClassifier( **params)\n",
    "    clf.fit(X_train,y_train)\n",
    "    score=clf.score(X_test,y_test)\n",
    "\n",
    "    return {'loss':-score, 'status': STATUS_OK }\n",
    "# Define the hyperparameter configuration space\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 200, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 50, 1),\n",
    "    \"max_features\":hp.quniform('max_features', 1, 20, 1),\n",
    "    \"min_samples_split\":hp.quniform('min_samples_split',2,11,1),\n",
    "    \"min_samples_leaf\":hp.quniform('min_samples_leaf',1,11,1),\n",
    "    \"criterion\":hp.choice('criterion',['gini','entropy'])\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hpo = RandomForestClassifier(n_estimators = 71, min_samples_leaf = 1, max_depth = 46, min_samples_split = 9, max_features = 20, criterion = 'entropy')\n",
    "rf_hpo.fit(X_train,y_train)\n",
    "rf_score=rf_hpo.score(X_test,y_test)\n",
    "y_predict=rf_hpo.predict(X_test)\n",
    "y_true=y_test\n",
    "print('Accuracy of RF: '+ str(rf_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_true, y_predict, average='weighted') \n",
    "print('Precision of RF: '+(str(precision)))\n",
    "print('Recall of RF: '+(str(recall)))\n",
    "print('F1-score of RF: '+(str(fscore)))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train=rf_hpo.predict(X_train)\n",
    "rf_test=rf_hpo.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 0)\n",
    "dt.fit(X_train,y_train) \n",
    "dt_score=dt.score(X_test,y_test)\n",
    "y_predict=dt.predict(X_test)\n",
    "y_true=y_test\n",
    "print('Accuracy of DT: '+ str(dt_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_true, y_predict, average='weighted') \n",
    "print('Precision of DT: '+(str(precision)))\n",
    "print('Recall of DT: '+(str(recall)))\n",
    "print('F1-score of DT: '+(str(fscore)))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization (HPO) of decision tree using Bayesian optimization with tree-based Parzen estimator (BO-TPE)\n",
    "Based on the GitHub repo for HPO: https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization of decision tree\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'max_features': int(params['max_features']),\n",
    "        \"min_samples_split\":int(params['min_samples_split']),\n",
    "        \"min_samples_leaf\":int(params['min_samples_leaf']),\n",
    "        \"criterion\":str(params['criterion'])\n",
    "    }\n",
    "    clf = DecisionTreeClassifier( **params)\n",
    "    clf.fit(X_train,y_train)\n",
    "    score=clf.score(X_test,y_test)\n",
    "\n",
    "    return {'loss':-score, 'status': STATUS_OK }\n",
    "# Define the hyperparameter configuration space\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 5, 50, 1),\n",
    "    \"max_features\":hp.quniform('max_features', 1, 20, 1),\n",
    "    \"min_samples_split\":hp.quniform('min_samples_split',2,11,1),\n",
    "    \"min_samples_leaf\":hp.quniform('min_samples_leaf',1,11,1),\n",
    "    \"criterion\":hp.choice('criterion',['gini','entropy'])\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50)\n",
    "print(\"Decision tree: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_hpo = DecisionTreeClassifier(min_samples_leaf = 2, max_depth = 47, min_samples_split = 3, max_features = 19, criterion = 'gini')\n",
    "dt_hpo.fit(X_train,y_train)\n",
    "dt_score=dt_hpo.score(X_test,y_test)\n",
    "y_predict=dt_hpo.predict(X_test)\n",
    "y_true=y_test\n",
    "print('Accuracy of DT: '+ str(dt_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_true, y_predict, average='weighted') \n",
    "print('Precision of DT: '+(str(precision)))\n",
    "print('Recall of DT: '+(str(recall)))\n",
    "print('F1-score of DT: '+(str(fscore)))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train=dt_hpo.predict(X_train)\n",
    "dt_test=dt_hpo.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(random_state = 0)\n",
    "et.fit(X_train,y_train) \n",
    "et_score=et.score(X_test,y_test)\n",
    "y_predict=et.predict(X_test)\n",
    "y_true=y_test\n",
    "print('Accuracy of ET: '+ str(et_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_true, y_predict, average='weighted') \n",
    "print('Precision of ET: '+(str(precision)))\n",
    "print('Recall of ET: '+(str(recall)))\n",
    "print('F1-score of ET: '+(str(fscore)))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization (HPO) of extra trees using Bayesian optimization with tree-based Parzen estimator (BO-TPE)\n",
    "Based on the GitHub repo for HPO: https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization of extra trees\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']), \n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'max_features': int(params['max_features']),\n",
    "        \"min_samples_split\":int(params['min_samples_split']),\n",
    "        \"min_samples_leaf\":int(params['min_samples_leaf']),\n",
    "        \"criterion\":str(params['criterion'])\n",
    "    }\n",
    "    clf = ExtraTreesClassifier( **params)\n",
    "    clf.fit(X_train,y_train)\n",
    "    score=clf.score(X_test,y_test)\n",
    "\n",
    "    return {'loss':-score, 'status': STATUS_OK }\n",
    "# Define the hyperparameter configuration space\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 200, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 50, 1),\n",
    "    \"max_features\":hp.quniform('max_features', 1, 20, 1),\n",
    "    \"min_samples_split\":hp.quniform('min_samples_split',2,11,1),\n",
    "    \"min_samples_leaf\":hp.quniform('min_samples_leaf',1,11,1),\n",
    "    \"criterion\":hp.choice('criterion',['gini','entropy'])\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_hpo = ExtraTreesClassifier(n_estimators = 53, min_samples_leaf = 1, max_depth = 31, min_samples_split = 5, max_features = 20, criterion = 'entropy')\n",
    "et_hpo.fit(X_train,y_train) \n",
    "et_score=et_hpo.score(X_test,y_test)\n",
    "y_predict=et_hpo.predict(X_test)\n",
    "y_true=y_test\n",
    "print('Accuracy of ET: '+ str(et_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_true, y_predict, average='weighted') \n",
    "print('Precision of ET: '+(str(precision)))\n",
    "print('Recall of ET: '+(str(recall)))\n",
    "print('F1-score of ET: '+(str(fscore)))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_train=et_hpo.predict(X_train)\n",
    "et_test=et_hpo.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Stacking\n",
    "The ensemble model that combines the four ML models (DT, RF, ET, XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictions_train = pd.DataFrame( {\n",
    "    'DecisionTree': dt_train.ravel(),\n",
    "        'RandomForest': rf_train.ravel(),\n",
    "     'ExtraTrees': et_train.ravel(),\n",
    "     'XgBoost': xg_train.ravel(),\n",
    "    })\n",
    "base_predictions_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train=dt_train.reshape(-1, 1)\n",
    "et_train=et_train.reshape(-1, 1)\n",
    "rf_train=rf_train.reshape(-1, 1)\n",
    "xg_train=xg_train.reshape(-1, 1)\n",
    "dt_test=dt_test.reshape(-1, 1)\n",
    "et_test=et_test.reshape(-1, 1)\n",
    "rf_test=rf_test.reshape(-1, 1)\n",
    "xg_test=xg_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(( dt_train, et_train, rf_train, xg_train), axis=1)\n",
    "x_test = np.concatenate(( dt_test, et_test, rf_test, xg_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stk = xgb.XGBClassifier().fit(x_train, y_train)\n",
    "y_predict=stk.predict(x_test)\n",
    "y_true=y_test\n",
    "stk_score=accuracy_score(y_true,y_predict)\n",
    "print('Accuracy of Stacking: '+ str(stk_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_true, y_predict, average='weighted') \n",
    "print('Precision of Stacking: '+(str(precision)))\n",
    "print('Recall of Stacking: '+(str(recall)))\n",
    "print('F1-score of Stacking: '+(str(fscore)))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization (HPO) of the stacking ensemble model (XGBoost) using Bayesian optimization with tree-based Parzen estimator (BO-TPE)\n",
    "Based on the GitHub repo for HPO: https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']), \n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'learning_rate':  abs(float(params['learning_rate'])),\n",
    "\n",
    "    }\n",
    "    clf = xgb.XGBClassifier( **params)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return {'loss':-score, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 100, 5),\n",
    "    'max_depth': hp.quniform('max_depth', 4, 100, 1),\n",
    "    'learning_rate': hp.normal('learning_rate', 0.01, 0.9),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"XGBoost: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = xgb.XGBClassifier(learning_rate= 0.19229249758051492, n_estimators = 30, max_depth = 36)\n",
    "xg.fit(x_train,y_train)\n",
    "xg_score=xg.score(x_test,y_test)\n",
    "y_predict=xg.predict(x_test)\n",
    "y_true=y_test\n",
    "print('Accuracy of XGBoost: '+ str(xg_score))\n",
    "precision,recall,fscore,none= precision_recall_fscore_support(y_true, y_predict, average='weighted') \n",
    "print('Precision of XGBoost: '+(str(precision)))\n",
    "print('Recall of XGBoost: '+(str(recall)))\n",
    "print('F1-score of XGBoost: '+(str(fscore)))\n",
    "print(classification_report(y_true,y_predict))\n",
    "cm=confusion_matrix(y_true,y_predict)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Anomaly-based IDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the port-scan datasets for unknown attack detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/CICIDS2017_sample_km.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['Label'] != 5]\n",
    "df1['Label'][df1['Label'] > 0] = 1\n",
    "df1.to_csv('./data/CICIDS2017_sample_km_without_portscan.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['Label'] == 5]\n",
    "df2['Label'][df2['Label'] == 5] = 1\n",
    "df2.to_csv('./data/CICIDS2017_sample_km_portscan.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the generated datasets for unknown attack detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data/CICIDS2017_sample_km_without_portscan.csv')\n",
    "df2 = pd.read_csv('./data/CICIDS2017_sample_km_portscan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df1.drop(['Label'],axis=1).dtypes[df1.dtypes != 'object'].index\n",
    "df1[features] = df1[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "df2[features] = df2[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "df1 = df1.fillna(0)\n",
    "df2 = df2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2p=df1[df1['Label']==0]\n",
    "df2pp=df2p.sample(n=None, frac=1255/18225, replace=False, weights=None, random_state=None, axis=0)\n",
    "df2=pd.concat([df2, df2pp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------ FIXED CODE BELOW 4371, This error occurs because the append method has been removed from pandas starting with version 2.0.0. The recommended approach is to use pandas.concat() instead.------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Label'],axis=1) .values\n",
    "y = df.iloc[:, -1].values.reshape(-1,1)\n",
    "y=np.ravel(y)\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering (IG, FCBF, and KPCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection by information gain (IG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "importances = mutual_info_classif(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of importance scores\n",
    "f_list = sorted(zip(map(lambda x: round(x, 4), importances), features), reverse=True)\n",
    "Sum = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list)):\n",
    "    Sum = Sum + f_list[i][0]\n",
    "    fs.append(f_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the important features from top to bottom until the accumulated importance reaches 90%\n",
    "f_list2 = sorted(zip(map(lambda x: round(x, 4), importances/Sum), features), reverse=True)\n",
    "Sum2 = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list2)):\n",
    "    Sum2 = Sum2 + f_list2[i][0]\n",
    "    fs.append(f_list2[i][1])\n",
    "    if Sum2>=0.9:\n",
    "        break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs = df[fs].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection by Fast Correlation Based Filter (FCBF)\n",
    "\n",
    "The module is imported from the GitHub repo: https://github.com/SantiagoEG/FCBF_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FCBF_module import FCBF, FCBFK, FCBFiP, get_i\n",
    "fcbf = FCBFK(k = 20)\n",
    "#fcbf.fit(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fss = fcbf.fit_transform(X_fs,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_fss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  kernel principal component analysis (KPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "kpca = KernelPCA(n_components = 10, kernel = 'rbf')\n",
    "kpca.fit(X_fss, y)\n",
    "X_kpca = kpca.transform(X_fss)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# kpca = PCA(n_components = 10)\n",
    "# kpca.fit(X_fss, y)\n",
    "# X_kpca = kpca.transform(X_fss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_kpca[:len(df1)]\n",
    "y_train = y[:len(df1)]\n",
    "X_test = X_kpca[len(df1):]\n",
    "y_test = y[len(df1):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve class-imbalance by SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ====== 4371 GROUP ENHANCEMENTS WILL BE IMPLEMENTED BELOW ======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# == Rationale for Implementing 4371 Group Enhancements Here ==\n",
    "\n",
    "\"\"\"\n",
    "This section introduces advanced anomaly detection models — Isolation Forest, Local Outlier Factor (LOF), \n",
    "and One-Class SVM — as enhancements to the Multi-Tiered Hybrid Intrusion Detection System (MTH-IDS). \n",
    "We are implementing these enhancements here, directly after the SMOTE-based class-balancing step, \n",
    "to ensure that the training data is balanced, which is critical for the effectiveness of anomaly detection models.\n",
    "\n",
    "### Why Implement Here?\n",
    "- **Balanced Data**: By placing these enhancements immediately after the data balancing step, we provide a more balanced dataset for our models, which can improve the reliability of outlier detection. Anomaly detection models like Isolation Forest and LOF are sensitive to class imbalance, and a balanced dataset can help them identify rare or unique attack patterns more effectively.\n",
    "- **Comparative Evaluation**: By positioning these models before the CL-k-means method, we can directly compare the performance of the new anomaly detection algorithms with the existing clustering-based approach, enabling a comprehensive analysis of detection capabilities.\n",
    "- **Logical Flow**: This location aligns well with the existing flow of the notebook, allowing us to introduce the additional models as part of the overall feature engineering and anomaly detection pipeline.\n",
    "\n",
    "### What We Hope to Achieve:\n",
    "1. **Enhanced Detection Capabilities**: Adding these models aims to improve MTH-IDS’s ability to detect both known and unknown types of attacks, particularly those that may be rare or hard to classify.\n",
    "2. **Reduced False Positives and False Negatives**: The voting mechanism we’ll implement will help aggregate predictions from multiple models, which can reduce the likelihood of false positives and false negatives, improving the overall accuracy and robustness of the system.\n",
    "3. **Adaptability to Unknown Attacks**: Models like One-Class SVM, which learns the normal behavior of the system, will help in flagging suspicious activities that do not conform to previously observed patterns, making MTH-IDS more adaptable to new and evolving threats.\n",
    "4. **Optimized Sensitivity**: With threshold optimization, we aim to balance the sensitivity of the IDS, minimizing false alarms while ensuring that actual threats are effectively detected.\n",
    "\n",
    "In summary, by implementing these enhancements here, we aim to create a more comprehensive and reliable intrusion detection system that can address a wider range of attack patterns, providing a robust solution for network security in the Internet of Vehicles (IoV) environment.\n",
    "\"\"\"\n",
    "# ===================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ====== END OF ENHANCEMENTS ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(n_jobs=-1,sampling_strategy={1:18225})\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the cluster labeling (CL) k-means method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN,MeanShift\n",
    "from sklearn.cluster import SpectralClustering,AgglomerativeClustering,AffinityPropagation,Birch,MiniBatchKMeans,MeanShift \n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CL_kmeans(X_train, X_test, y_train, y_test,n,b=100):\n",
    "    km_cluster = MiniBatchKMeans(n_clusters=n,batch_size=b)\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y_test, result2))\n",
    "    cm=confusion_matrix(y_test,result2)\n",
    "    acc=metrics.accuracy_score(y_test,result2)\n",
    "    print(str(acc))\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_kmeans(X_train, X_test, y_train, y_test, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization of CL-k-means\n",
    "Tune \"k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----- ADDED LINE BELOW 4371  Python is unable to find the skopt module because it hasn't been installed yet. -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install --upgrade scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "import numpy as np\n",
    "np.int = int\n",
    "print(f\"scikit-optimize version: {skopt.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by BO-GP\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import MiniBatchKMeans # 4371 ADDED TO FIX ERROR OF minibatchkmeans NOT BEING IMPORTED\n",
    "\n",
    "space  = [Integer(2, 50, name='n_clusters')]\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    km_cluster = MiniBatchKMeans(batch_size=100, **params)\n",
    "    n=params['n_clusters']\n",
    "    \n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    cm=metrics.accuracy_score(y_test,result2)\n",
    "    print(str(n)+\" \"+str(cm))\n",
    "    return (1-cm)\n",
    "from skopt import gp_minimize\n",
    "import time\n",
    "t1=time.time()\n",
    "try:\n",
    "    res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "    print(\"Best score=%.4f\" % (1 - res_gp.fun))\n",
    "    print(\"Best parameters: n_clusters=%d\" % res_gp.x[0])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by BO-TPE\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_clusters': int(params['n_clusters']), \n",
    "    }\n",
    "    km_cluster = MiniBatchKMeans(batch_size=100, **params)\n",
    "    n=params['n_clusters']\n",
    "    \n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    score=metrics.accuracy_score(y_test,result2)\n",
    "    print(str(params['n_clusters'])+\" \"+str(score))\n",
    "    return {'loss':1-score, 'status': STATUS_OK }\n",
    "space = {\n",
    "    'n_clusters': hp.quniform('n_clusters', 2, 50, 1),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_kmeans(X_train, X_test, y_train, y_test, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the CL-k-means model with biased classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only a sample code to show the logic. It needs to work on the entire dataset to generate sufficient training samples for biased classifiers\n",
    "def Anomaly_IDS(X_train, X_test, y_train, y_test,n,b=100):\n",
    "    # CL-kmeans\n",
    "    km_cluster = MiniBatchKMeans(n_clusters=n,batch_size=b)\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y_train)):\n",
    "            if result[i]==v:\n",
    "                if y_train[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y_test, result2))\n",
    "    cm=confusion_matrix(y_test,result2)\n",
    "    acc=metrics.accuracy_score(y2,result2)\n",
    "    print(str(acc))\n",
    "    print(cm)\n",
    "    \n",
    "    #Biased classifier construction\n",
    "    count=0\n",
    "    print(len(y))\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    FNL=[]\n",
    "    FPL=[]\n",
    "    for v in range(0,n):\n",
    "        al=[]\n",
    "        bl=[]\n",
    "        for i in range(0,len(y)):   \n",
    "            if result[i]==v:        \n",
    "                if y[i]==1:        #label 1\n",
    "                    a[v]=a[v]+1\n",
    "                    al.append(i)\n",
    "                else:             #label 0\n",
    "                    b[v]=b[v]+1\n",
    "                    bl.append(i)\n",
    "        if a[v]<=b[v]:\n",
    "            FNL.extend(al)\n",
    "        else:\n",
    "            FPL.extend(bl)\n",
    "        #print(str(v)+\"=\"+str(a[v]/(a[v]+b[v])))\n",
    "        \n",
    "    dffp=df.iloc[FPL, :]\n",
    "    dffn=df.iloc[FNL, :]\n",
    "    dfva0=df[df['Label']==0]\n",
    "    dfva1=df[df['Label']==1]\n",
    "    \n",
    "    dffpp=dfva1.sample(n=None, frac=len(FPL)/dfva1.shape[0], replace=False, weights=None, random_state=None, axis=0)\n",
    "    dffnp=dfva0.sample(n=None, frac=len(FNL)/dfva0.shape[0], replace=False, weights=None, random_state=None, axis=0)\n",
    "    \n",
    "    dffp_f=pd.concat([dffp, dffpp])\n",
    "    dffn_f=pd.concat([dffn, dffnp])\n",
    "    \n",
    "    Xp = dffp_f.drop(['Label'],axis=1)  \n",
    "    yp = dffp_f.iloc[:, -1].values.reshape(-1,1)\n",
    "    yp=np.ravel(yp)\n",
    "\n",
    "    Xn = dffn_f.drop(['Label'],axis=1)  \n",
    "    yn = dffn_f.iloc[:, -1].values.reshape(-1,1)\n",
    "    yn=np.ravel(yn)\n",
    "    \n",
    "    rfp = RandomForestClassifier(random_state = 0)\n",
    "    rfp.fit(Xp,yp)\n",
    "    rfn = RandomForestClassifier(random_state = 0)\n",
    "    rfn.fit(Xn,yn)\n",
    "\n",
    "    dffnn_f=pd.concat([dffn, dffnp])\n",
    "    \n",
    "    Xnn = dffn_f.drop(['Label'],axis=1)  \n",
    "    ynn = dffn_f.iloc[:, -1].values.reshape(-1,1)\n",
    "    ynn=np.ravel(ynn)\n",
    "\n",
    "    rfnn = RandomForestClassifier(random_state = 0)\n",
    "    rfnn.fit(Xnn,ynn)\n",
    "\n",
    "    X2p = df2.drop(['Label'],axis=1) \n",
    "    y2p = df2.iloc[:, -1].values.reshape(-1,1)\n",
    "    y2p=np.ravel(y2p)\n",
    "\n",
    "    result2 = km_cluster.predict(X2p)\n",
    "\n",
    "    count=0\n",
    "    a=np.zeros(n)\n",
    "    b=np.zeros(n)\n",
    "    for v in range(0,n):\n",
    "        for i in range(0,len(y)):\n",
    "            if result[i]==v:\n",
    "                if y[i]==1:\n",
    "                    a[v]=a[v]+1\n",
    "                else:\n",
    "                    b[v]=b[v]+1\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    l1=[]\n",
    "    l0=[]\n",
    "    for v in range(0,n):\n",
    "        if a[v]<=b[v]:\n",
    "            list1.append(v)\n",
    "        else: \n",
    "            list2.append(v)\n",
    "    for v in range(0,len(y2p)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v]=0\n",
    "            l0.append(v)\n",
    "        elif result2[v] in list2:\n",
    "            result2[v]=1\n",
    "            l1.append(v)\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y2p, result2))\n",
    "    cm=confusion_matrix(y2p,result2)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% of the code has been shared, and the remaining 5% is retained for future extension.  \n",
    "Thank you for your interest and more details are in the paper."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
